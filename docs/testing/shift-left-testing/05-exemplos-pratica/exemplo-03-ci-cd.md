# âš™ï¸ Exemplo 03: Pipeline CI/CD

> **Objetivo**: Demonstrar configuraÃ§Ã£o completa de pipeline CI/CD com princÃ­pios Shift Left

## ğŸ“‹ Contexto

Este exemplo apresenta o pipeline GitHub Actions do projeto CNPJ-QA-Training, explicando como cada estÃ¡gio implementa princÃ­pios de Shift Left Testing.

## ğŸ—ï¸ Arquitetura do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PIPELINE SHIFT LEFT                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  TRIGGER: push/PR para master                                           â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚ quality-checks  â”‚ â† PRIMEIRO: VerificaÃ§Ãµes rÃ¡pidas                   â”‚
â”‚  â”‚ â€¢ lint (flake8) â”‚   Tempo: ~30s                                      â”‚
â”‚  â”‚ â€¢ format (black)â”‚   Fail Fast: CÃ³digo mal formatado para aqui       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚           â”‚ needs                                                        â”‚
â”‚           â–¼                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚   unit-tests    â”‚ â† SEGUNDO: Testes unitÃ¡rios                        â”‚
â”‚  â”‚ â€¢ matrix 3.8-11 â”‚   Tempo: ~2min                                     â”‚
â”‚  â”‚ â€¢ pytest + cov  â”‚   Fail Fast: Bug lÃ³gico para aqui                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚           â”‚ needs                                                        â”‚
â”‚           â–¼                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚integration-testsâ”‚ â† TERCEIRO: Testes de integraÃ§Ã£o                   â”‚
â”‚  â”‚ â€¢ mocks         â”‚   Tempo: ~3min                                     â”‚
â”‚  â”‚ â€¢ e2e (select)  â”‚   Fail Fast: Problemas de integraÃ§Ã£o              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚           â”‚ needs                                                        â”‚
â”‚           â–¼                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚    security     â”‚ â† QUARTO: VerificaÃ§Ãµes de seguranÃ§a                â”‚
â”‚  â”‚ â€¢ bandit (SAST) â”‚   Tempo: ~1min                                     â”‚
â”‚  â”‚ â€¢ safety (deps) â”‚   Fail Fast: Vulnerabilidades                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚                                                                          â”‚
â”‚  TOTAL: ~7min (se tudo passar)                                          â”‚
â”‚  FAIL FAST: Feedback em segundos se houver problema                     â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“„ Arquivo de Workflow Completo

```yaml
# .github/workflows/ci-cd.yml

name: CI/CD Pipeline

# ============================================================
# TRIGGERS
# ============================================================
on:
  push:
    branches: [master, main]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    branches: [master, main]
  schedule:
    # Roda diariamente Ã s 6h UTC para verificar dependÃªncias
    - cron: '0 6 * * *'

# ============================================================
# VARIÃVEIS DE AMBIENTE GLOBAIS
# ============================================================
env:
  PYTHON_DEFAULT_VERSION: '3.11'
  COVERAGE_THRESHOLD: 80

# ============================================================
# JOBS
# ============================================================
jobs:
  # ----------------------------------------------------------
  # JOB 1: QUALITY CHECKS
  # Executa primeiro para feedback rÃ¡pido
  # ----------------------------------------------------------
  quality-checks:
    name: ğŸ” Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort
      
      - name: ğŸ” Lint com flake8
        run: |
          # Erros crÃ­ticos que quebram o build
          flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
          # Warnings que geram alerta mas nÃ£o quebram
          flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: ğŸ¨ Verificar formataÃ§Ã£o com black
        run: black --check --diff src/ tests/
      
      - name: ğŸ“‹ Verificar imports com isort
        run: isort --check-only --diff src/ tests/

  # ----------------------------------------------------------
  # JOB 2: UNIT TESTS
  # Roda apÃ³s quality-checks passar
  # ----------------------------------------------------------
  unit-tests:
    name: ğŸ§ª Unit Tests (Python ${{ matrix.python-version }})
    needs: quality-checks
    runs-on: ubuntu-latest
    
    strategy:
      fail-fast: true  # Para imediatamente se um falhar
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-xdist
      
      - name: ğŸ§ª Executar testes unitÃ¡rios
        run: |
          pytest tests/ \
            --ignore=tests/test_integration.py \
            -v \
            --tb=short \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=${{ env.COVERAGE_THRESHOLD }} \
            -n auto  # Paralelo
      
      - name: ğŸ“Š Upload cobertura para Codecov
        if: matrix.python-version == env.PYTHON_DEFAULT_VERSION
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: unittests
          fail_ci_if_error: true
          token: ${{ secrets.CODECOV_TOKEN }}

  # ----------------------------------------------------------
  # JOB 3: INTEGRATION TESTS
  # Roda apÃ³s unit-tests passar
  # ----------------------------------------------------------
  integration-tests:
    name: ğŸ”— Integration Tests
    needs: unit-tests
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest responses
      
      - name: ğŸ”— Executar testes de integraÃ§Ã£o
        run: |
          pytest tests/test_integration.py \
            -v \
            --tb=long \
            -m "not e2e"  # Exclui E2E em PRs

  # ----------------------------------------------------------
  # JOB 4: SECURITY CHECKS
  # Roda apÃ³s integration-tests passar
  # ----------------------------------------------------------
  security:
    name: ğŸ”’ Security Checks
    needs: integration-tests
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Instalar ferramentas de seguranÃ§a
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety pip-audit
      
      - name: ğŸ” SAST com Bandit
        run: |
          bandit -r src/ \
            -f json \
            -o bandit-report.json \
            --severity-level medium \
            --confidence-level medium \
            || true  # NÃ£o falha, apenas reporta
      
      - name: ğŸ“‹ Safety Check (dependÃªncias)
        run: |
          pip install -r requirements.txt
          safety check --full-report
        continue-on-error: true
      
      - name: ğŸ” pip-audit
        run: pip-audit
        continue-on-error: true
      
      - name: ğŸ“¤ Upload relatÃ³rio de seguranÃ§a
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json

  # ----------------------------------------------------------
  # JOB 5: BUILD & PUBLISH (apenas em push para master)
  # ----------------------------------------------------------
  build:
    name: ğŸ“¦ Build Package
    needs: security
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/master'
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
      
      - name: ğŸ“¦ Build package
        run: |
          pip install build
          python -m build
      
      - name: ğŸ“¤ Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/

  # ----------------------------------------------------------
  # JOB 6: E2E TESTS (Apenas em schedule)
  # ----------------------------------------------------------
  e2e-tests:
    name: ğŸŒ E2E Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
      
      - name: ğŸ“¦ Instalar dependÃªncias
        run: |
          pip install -r requirements.txt
          pip install pytest
      
      - name: ğŸŒ Executar testes E2E
        env:
          RECEITA_API_KEY: ${{ secrets.RECEITA_API_KEY }}
        run: |
          pytest tests/ -m "e2e" -v --tb=long
        continue-on-error: true  # NÃ£o bloqueia schedule
```

## ğŸ¯ PrincÃ­pios Shift Left Aplicados

### 1. Fail Fast - Ordem dos Jobs

```yaml
jobs:
  quality-checks:    # ~30s - Mais rÃ¡pido
    ...
  unit-tests:        # ~2min - Segundo
    needs: quality-checks
  integration-tests: # ~3min - Terceiro
    needs: unit-tests
  security:          # ~1min - Quarto
    needs: integration-tests
```

**Por quÃª?** Problemas de lint sÃ£o detectados em 30 segundos, nÃ£o em 7 minutos.

### 2. Matrix Testing - MÃºltiplas VersÃµes

```yaml
strategy:
  fail-fast: true
  matrix:
    python-version: ['3.8', '3.9', '3.10', '3.11']
```

**Por quÃª?** Encontra incompatibilidades antes de chegar nos usuÃ¡rios.

### 3. Cobertura com Threshold

```yaml
--cov-fail-under=${{ env.COVERAGE_THRESHOLD }}
```

**Por quÃª?** Impede merge de cÃ³digo sem testes adequados.

### 4. SeguranÃ§a Integrada

```yaml
security:
  needs: integration-tests
  steps:
    - bandit   # SAST
    - safety   # DependÃªncias
    - pip-audit
```

**Por quÃª?** Vulnerabilidades sÃ£o encontradas antes do deploy.

### 5. Testes E2E Separados

```yaml
e2e-tests:
  if: github.event_name == 'schedule'
```

**Por quÃª?** Testes lentos/flaky nÃ£o bloqueiam PRs mas ainda sÃ£o executados.

## ğŸ“Š ConfiguraÃ§Ã£o Adicional: pytest.ini

```ini
# pytest.ini

[pytest]
# DiretÃ³rios de teste
testpaths = tests

# PadrÃµes de arquivo
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Markers customizados
markers =
    smoke: Testes de sanidade rÃ¡pidos
    unit: Testes unitÃ¡rios
    integration: Testes de integraÃ§Ã£o
    e2e: Testes end-to-end
    slow: Testes lentos

# OpÃ§Ãµes padrÃ£o
addopts = 
    -v
    --tb=short
    --strict-markers
    -ra

# Cobertura
cov-report = term-missing
cov-fail-under = 80

# Warnings
filterwarnings =
    error
    ignore::DeprecationWarning
```

## ğŸ“Š ConfiguraÃ§Ã£o: pyproject.toml

```toml
# pyproject.toml

[tool.black]
line-length = 127
target-version = ['py38', 'py39', 'py310', 'py311']
include = '\.pyi?$'
exclude = '''
/(
    \.git
    | \.hg
    | \.mypy_cache
    | \.tox
    | \.venv
    | _build
    | buck-out
    | build
    | dist
)/
'''

[tool.isort]
profile = "black"
line_length = 127
known_first_party = ["cnpj_validator"]

[tool.bandit]
exclude_dirs = ["tests", "docs"]
skips = ["B101"]  # assert ok em testes

[tool.coverage.run]
source = ["src"]
branch = true
omit = ["*/tests/*", "*/__pycache__/*"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
]
```

## ğŸ”§ Scripts de Suporte

### run-tests.bat (Windows)

```batch
@echo off
REM scripts/run-tests.bat

echo ====================================
echo    CNPJ Validator - Test Runner
echo ====================================

REM Ativa ambiente virtual se existir
if exist "venv\Scripts\activate.bat" (
    call venv\Scripts\activate.bat
)

echo.
echo [1/4] Quality Checks...
echo --------------------------------
python -m flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source
if %ERRORLEVEL% NEQ 0 (
    echo ERRO: Lint falhou!
    exit /b 1
)

python -m black --check src/ tests/
if %ERRORLEVEL% NEQ 0 (
    echo ERRO: Formatacao incorreta! Execute: black src/ tests/
    exit /b 1
)

echo.
echo [2/4] Unit Tests...
echo --------------------------------
python -m pytest tests/ --ignore=tests/test_integration.py -v --tb=short --cov=src --cov-report=term-missing
if %ERRORLEVEL% NEQ 0 (
    echo ERRO: Testes unitarios falharam!
    exit /b 1
)

echo.
echo [3/4] Integration Tests...
echo --------------------------------
python -m pytest tests/test_integration.py -v --tb=short
if %ERRORLEVEL% NEQ 0 (
    echo ERRO: Testes de integracao falharam!
    exit /b 1
)

echo.
echo [4/4] Security Checks...
echo --------------------------------
python -m bandit -r src/ -ll
python -m safety check

echo.
echo ====================================
echo    TODOS OS TESTES PASSARAM!
echo ====================================
```

### run-tests.sh (Linux/Mac)

```bash
#!/bin/bash
# scripts/run-tests.sh

set -e  # Exit on error

echo "===================================="
echo "   CNPJ Validator - Test Runner"
echo "===================================="

# Ativa ambiente virtual se existir
if [ -f "venv/bin/activate" ]; then
    source venv/bin/activate
fi

echo ""
echo "[1/4] Quality Checks..."
echo "--------------------------------"
python -m flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source
python -m black --check src/ tests/

echo ""
echo "[2/4] Unit Tests..."
echo "--------------------------------"
python -m pytest tests/ \
    --ignore=tests/test_integration.py \
    -v \
    --tb=short \
    --cov=src \
    --cov-report=term-missing \
    --cov-fail-under=80

echo ""
echo "[3/4] Integration Tests..."
echo "--------------------------------"
python -m pytest tests/test_integration.py -v --tb=short

echo ""
echo "[4/4] Security Checks..."
echo "--------------------------------"
python -m bandit -r src/ -ll
python -m safety check || true

echo ""
echo "===================================="
echo "   TODOS OS TESTES PASSARAM!"
echo "===================================="
```

## ğŸ“ˆ MÃ©tricas do Pipeline

| EstÃ¡gio | Tempo MÃ©dio | Objetivo |
|---------|-------------|----------|
| quality-checks | 30s | < 1min |
| unit-tests | 2min | < 5min |
| integration-tests | 3min | < 5min |
| security | 1min | < 2min |
| **Total** | **~7min** | **< 15min** |

## ğŸ”— PrÃ³ximos Passos

- [Exemplo 04: AutomaÃ§Ã£o Completa](exemplo-04-automacao.md)
- [ExercÃ­cios PrÃ¡ticos](../03-exercicios/index.md)

---

| Anterior | Ãndice | PrÃ³ximo |
|----------|--------|---------|
| [â† Integration](exemplo-02-integration.md) | [ğŸ“š Principal](../README.md) | [AutomaÃ§Ã£o â†’](exemplo-04-automacao.md) |
