# ğŸ“ Gabarito - NÃ­vel IntermediÃ¡rio

> **ExercÃ­cios 4-6** | Tempo de RevisÃ£o: ~45 minutos

---

## ExercÃ­cio 4: AnÃ¡lise de CÃ³digo Legado

### ğŸ“‹ Enunciado Resumido
Analisar cÃ³digo legado do validador CNPJ e propor melhorias testÃ¡veis seguindo princÃ­pios Shift Left.

### âœ… Resposta Esperada

#### 4.1 Problemas Identificados

```python
# CÃ“DIGO ORIGINAL (problemÃ¡tico)
def validate_cnpj(cnpj):
    # Problema 1: Sem validaÃ§Ã£o de entrada
    # Problema 2: LÃ³gica complexa em um Ãºnico mÃ©todo
    # Problema 3: Sem tratamento de erros especÃ­ficos
    # Problema 4: Sem documentaÃ§Ã£o
    # Problema 5: DifÃ­cil de testar (alto acoplamento)
    
    cnpj = cnpj.replace('.', '').replace('/', '').replace('-', '')
    if len(cnpj) != 14:
        return False
    # ... mais lÃ³gica misturada
```

**AnÃ¡lise Detalhada**:

| # | Problema | Impacto | PrincÃ­pio Shift Left Violado |
|---|----------|---------|------------------------------|
| 1 | Sem validaÃ§Ã£o de entrada | Comportamento indefinido com None/tipos errados | Fail Fast |
| 2 | FunÃ§Ã£o monolÃ­tica | DifÃ­cil testar partes isoladas | Testabilidade |
| 3 | Retorna apenas bool | NÃ£o informa qual problema ocorreu | Feedback ContÃ­nuo |
| 4 | Sem docstrings | DifÃ­cil entender comportamento esperado | DocumentaÃ§Ã£o |
| 5 | Acoplamento alto | MudanÃ§a em uma parte quebra outras | Modularidade |

#### 4.2 CÃ³digo Refatorado

```python
"""
MÃ³dulo de validaÃ§Ã£o de CNPJ com design testÃ¡vel.
Segue princÃ­pios Shift Left para facilitar testes automatizados.
"""
from dataclasses import dataclass
from typing import Union
from enum import Enum


class CNPJValidationError(Exception):
    """ExceÃ§Ã£o base para erros de validaÃ§Ã£o de CNPJ."""
    pass


class ValidationResult(Enum):
    """Resultados possÃ­veis da validaÃ§Ã£o."""
    VALID = "valid"
    INVALID_FORMAT = "invalid_format"
    INVALID_LENGTH = "invalid_length"
    INVALID_DIGITS = "invalid_digits"
    INVALID_CHECKSUM = "invalid_checksum"


@dataclass
class CNPJValidationReport:
    """RelatÃ³rio detalhado de validaÃ§Ã£o."""
    is_valid: bool
    result: ValidationResult
    message: str
    original_input: str
    sanitized_input: str = ""
    
    def __bool__(self):
        return self.is_valid


class CNPJValidator:
    """
    Validador de CNPJ com design orientado a testes.
    
    PrincÃ­pios aplicados:
    - Single Responsibility: cada mÃ©todo faz uma coisa
    - Fail Fast: validaÃ§Ãµes na entrada
    - Feedback Rico: relatÃ³rios detalhados
    
    Exemplo:
        >>> validator = CNPJValidator()
        >>> result = validator.validate("11.222.333/0001-81")
        >>> print(result.is_valid)
        True
    """
    
    # Constantes para facilitar testes
    CNPJ_LENGTH = 14
    FIRST_MULTIPLIERS = [5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
    SECOND_MULTIPLIERS = [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
    
    def validate(self, cnpj: Union[str, None]) -> CNPJValidationReport:
        """
        Valida um CNPJ e retorna relatÃ³rio detalhado.
        
        Args:
            cnpj: String contendo CNPJ (com ou sem formataÃ§Ã£o)
            
        Returns:
            CNPJValidationReport com resultado detalhado
            
        Raises:
            CNPJValidationError: Se input for None ou tipo invÃ¡lido
        """
        # Fail Fast: validaÃ§Ã£o de entrada
        if cnpj is None:
            raise CNPJValidationError("CNPJ nÃ£o pode ser None")
        
        if not isinstance(cnpj, str):
            raise CNPJValidationError(f"CNPJ deve ser string, recebido {type(cnpj)}")
        
        original = cnpj
        
        # Etapa 1: SanitizaÃ§Ã£o
        sanitized = self._sanitize(cnpj)
        
        # Etapa 2: ValidaÃ§Ã£o de formato
        format_result = self._validate_format(sanitized)
        if format_result:
            return CNPJValidationReport(
                is_valid=False,
                result=format_result,
                message=self._get_message(format_result),
                original_input=original,
                sanitized_input=sanitized
            )
        
        # Etapa 3: ValidaÃ§Ã£o de dÃ­gitos verificadores
        if not self._validate_check_digits(sanitized):
            return CNPJValidationReport(
                is_valid=False,
                result=ValidationResult.INVALID_CHECKSUM,
                message="DÃ­gitos verificadores invÃ¡lidos",
                original_input=original,
                sanitized_input=sanitized
            )
        
        # Sucesso
        return CNPJValidationReport(
            is_valid=True,
            result=ValidationResult.VALID,
            message="CNPJ vÃ¡lido",
            original_input=original,
            sanitized_input=sanitized
        )
    
    def _sanitize(self, cnpj: str) -> str:
        """Remove caracteres nÃ£o numÃ©ricos."""
        return ''.join(c for c in cnpj if c.isdigit())
    
    def _validate_format(self, cnpj: str) -> Union[ValidationResult, None]:
        """Valida formato do CNPJ sanitizado."""
        if len(cnpj) != self.CNPJ_LENGTH:
            return ValidationResult.INVALID_LENGTH
        
        if not cnpj.isdigit():
            return ValidationResult.INVALID_DIGITS
        
        # CNPJs com todos dÃ­gitos iguais sÃ£o invÃ¡lidos
        if len(set(cnpj)) == 1:
            return ValidationResult.INVALID_FORMAT
        
        return None  # Formato OK
    
    def _validate_check_digits(self, cnpj: str) -> bool:
        """Valida os dois dÃ­gitos verificadores."""
        first_digit = self._calculate_digit(cnpj[:12], self.FIRST_MULTIPLIERS)
        second_digit = self._calculate_digit(cnpj[:13], self.SECOND_MULTIPLIERS)
        
        return cnpj[12] == str(first_digit) and cnpj[13] == str(second_digit)
    
    def _calculate_digit(self, base: str, multipliers: list) -> int:
        """Calcula um dÃ­gito verificador."""
        total = sum(int(d) * m for d, m in zip(base, multipliers))
        remainder = total % 11
        return 0 if remainder < 2 else 11 - remainder
    
    def _get_message(self, result: ValidationResult) -> str:
        """Retorna mensagem amigÃ¡vel para cada tipo de erro."""
        messages = {
            ValidationResult.INVALID_FORMAT: "Formato de CNPJ invÃ¡lido",
            ValidationResult.INVALID_LENGTH: f"CNPJ deve ter {self.CNPJ_LENGTH} dÃ­gitos",
            ValidationResult.INVALID_DIGITS: "CNPJ deve conter apenas dÃ­gitos",
            ValidationResult.INVALID_CHECKSUM: "DÃ­gitos verificadores invÃ¡lidos",
        }
        return messages.get(result, "Erro desconhecido")
```

#### 4.3 Testes para CÃ³digo Refatorado

```python
import pytest
from cnpj_validator_refactored import (
    CNPJValidator, 
    CNPJValidationError,
    ValidationResult
)


class TestCNPJValidatorSanitize:
    """Testes isolados para o mÃ©todo _sanitize."""
    
    @pytest.fixture
    def validator(self):
        return CNPJValidator()
    
    def test_sanitize_remove_pontuacao(self, validator):
        assert validator._sanitize("11.222.333/0001-81") == "11222333000181"
    
    def test_sanitize_mantem_numeros(self, validator):
        assert validator._sanitize("11222333000181") == "11222333000181"
    
    def test_sanitize_remove_espacos(self, validator):
        assert validator._sanitize(" 11 222 333 ") == "11222333"


class TestCNPJValidatorFormat:
    """Testes isolados para validaÃ§Ã£o de formato."""
    
    @pytest.fixture
    def validator(self):
        return CNPJValidator()
    
    def test_format_tamanho_correto_retorna_none(self, validator):
        assert validator._validate_format("11222333000181") is None
    
    def test_format_tamanho_incorreto_retorna_erro(self, validator):
        result = validator._validate_format("1122233300018")  # 13 dÃ­gitos
        assert result == ValidationResult.INVALID_LENGTH
    
    def test_format_digitos_iguais_retorna_erro(self, validator):
        result = validator._validate_format("11111111111111")
        assert result == ValidationResult.INVALID_FORMAT


class TestCNPJValidatorCheckDigits:
    """Testes isolados para cÃ¡lculo de dÃ­gitos verificadores."""
    
    @pytest.fixture
    def validator(self):
        return CNPJValidator()
    
    def test_calcula_primeiro_digito(self, validator):
        # CNPJ: 11.222.333/0001-81
        # Primeiro dÃ­gito verificador: 8
        digito = validator._calculate_digit("112223330001", validator.FIRST_MULTIPLIERS)
        assert digito == 8
    
    def test_calcula_segundo_digito(self, validator):
        # CNPJ: 11.222.333/0001-81
        # Segundo dÃ­gito verificador: 1
        digito = validator._calculate_digit("1122233300018", validator.SECOND_MULTIPLIERS)
        assert digito == 1
    
    def test_validate_check_digits_valido(self, validator):
        assert validator._validate_check_digits("11222333000181") is True
    
    def test_validate_check_digits_invalido(self, validator):
        assert validator._validate_check_digits("11222333000182") is False


class TestCNPJValidatorIntegration:
    """Testes de integraÃ§Ã£o do validador completo."""
    
    @pytest.fixture
    def validator(self):
        return CNPJValidator()
    
    def test_cnpj_valido_retorna_report_positivo(self, validator):
        result = validator.validate("11.222.333/0001-81")
        
        assert result.is_valid is True
        assert result.result == ValidationResult.VALID
        assert bool(result) is True
    
    def test_cnpj_invalido_retorna_report_negativo(self, validator):
        result = validator.validate("11.222.333/0001-82")
        
        assert result.is_valid is False
        assert result.result == ValidationResult.INVALID_CHECKSUM
        assert bool(result) is False
    
    def test_cnpj_none_levanta_excecao(self, validator):
        with pytest.raises(CNPJValidationError) as exc:
            validator.validate(None)
        assert "None" in str(exc.value)
    
    def test_cnpj_tipo_errado_levanta_excecao(self, validator):
        with pytest.raises(CNPJValidationError) as exc:
            validator.validate(12345)
        assert "string" in str(exc.value)
    
    @pytest.mark.parametrize("cnpj,expected_valid", [
        ("11.222.333/0001-81", True),
        ("11222333000181", True),
        ("00.000.000/0001-91", True),
        ("11.222.333/0001-82", False),  # DÃ­gito errado
        ("11111111111111", False),       # DÃ­gitos iguais
        ("1234567890123", False),        # Tamanho errado
    ])
    def test_diversos_cnpjs(self, validator, cnpj, expected_valid):
        result = validator.validate(cnpj)
        assert result.is_valid == expected_valid
```

### ğŸ’¡ Por Que Funciona

**1. SeparaÃ§Ã£o de Responsabilidades**
- Cada mÃ©todo privado faz UMA coisa
- Facilita testar cada parte isoladamente
- MudanÃ§a em uma parte nÃ£o quebra outras

**2. Fail Fast**
- ExceÃ§Ãµes explÃ­citas para entradas invÃ¡lidas
- NÃ£o tenta processar dados ruins
- Feedback imediato

**3. Rich Feedback**
- `ValidationResult` enum com todos os casos
- `CNPJValidationReport` com contexto completo
- Mensagens amigÃ¡veis para debug

**4. Testabilidade**
- MÃ©todos pÃºblicos e privados testÃ¡veis
- Fixtures simplificam setup
- ParametrizaÃ§Ã£o cobre muitos casos

### âš ï¸ Erros Comuns

1. **Refatorar sem testes primeiro**
   - Sempre escreva testes ANTES de refatorar
   - Garante que comportamento Ã© preservado

2. **Over-engineering**
   - NÃ£o precisa de 10 classes para um validador simples
   - Balance entre testabilidade e complexidade

3. **Ignorar casos de borda**
   - None, string vazia, tipos errados
   - CNPJs com todos dÃ­gitos iguais

4. **Testes muito acoplados Ã  implementaÃ§Ã£o**
   - Testar comportamento, nÃ£o implementaÃ§Ã£o
   - Se mÃ©todo interno muda, teste nÃ£o deveria quebrar

### ğŸ”„ Alternativas AceitÃ¡veis

- Usar funÃ§Ãµes ao invÃ©s de classe (programaÃ§Ã£o funcional)
- Retornar tupla (bool, mensagem) ao invÃ©s de dataclass
- Usar validaÃ§Ã£o com decorators
- Implementar como pipeline de validaÃ§Ãµes

### ğŸ“š ConexÃ£o com a Teoria

- [03-como-funciona.md](../02-guia-teorico/03-como-funciona.md) - Design TestÃ¡vel
- [04-como-aplicar.md](../02-guia-teorico/04-como-aplicar.md) - RefatoraÃ§Ã£o

### ğŸ¯ Pontos de DiscussÃ£o

1. "Como decidir quando uma funÃ§Ã£o estÃ¡ grande demais?"
2. "Testar mÃ©todos privados Ã© boa prÃ¡tica?"
3. "ExceÃ§Ã£o vs retorno de erro - quando usar cada um?"

---

## ExercÃ­cio 5: EstratÃ©gia de IntegraÃ§Ã£o

### ğŸ“‹ Enunciado Resumido
Desenhar estratÃ©gia de testes de integraÃ§Ã£o para comunicaÃ§Ã£o entre validador CNPJ e API da Receita Federal.

### âœ… Resposta Esperada

#### 5.1 Arquitetura de Testes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIRÃ‚MIDE DE TESTES - INTEGRAÃ‡ÃƒO              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                         â”‚   E2E   â”‚  (Poucos, Lentos, Caros)    â”‚
â”‚                         â”‚ Receita â”‚                              â”‚
â”‚                       â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”                            â”‚
â”‚                       â”‚ IntegraÃ§Ã£o  â”‚  â† FOCO DESTE EXERCÃCIO   â”‚
â”‚                       â”‚   Mock API  â”‚                            â”‚
â”‚                     â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”                          â”‚
â”‚                     â”‚   Contrato API   â”‚  (Validam interface)    â”‚
â”‚                   â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”                        â”‚
â”‚                   â”‚    UnitÃ¡rios CNPJ    â”‚  (Muitos, RÃ¡pidos)    â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.2 NÃ­veis de Teste

| NÃ­vel | PropÃ³sito | Velocidade | DependÃªncias |
|-------|-----------|------------|--------------|
| UnitÃ¡rio | LÃ³gica de validaÃ§Ã£o | < 100ms | Nenhuma |
| Contrato | Interface da API | < 500ms | Schema JSON |
| IntegraÃ§Ã£o (Mock) | Fluxo completo | < 2s | Mock server |
| E2E (Real) | ValidaÃ§Ã£o real | < 10s | API Receita |

#### 5.3 ImplementaÃ§Ã£o com Mocks

```python
"""
Testes de integraÃ§Ã£o com mock da API da Receita Federal.
Usa responses para simular respostas HTTP sem chamar API real.
"""
import pytest
import responses
from cnpj_validator import CNPJService


class TestCNPJServiceIntegration:
    """Testes de integraÃ§Ã£o do serviÃ§o CNPJ."""
    
    BASE_URL = "https://receitaws.com.br/v1/cnpj"
    
    @pytest.fixture
    def service(self):
        return CNPJService()
    
    # --- CenÃ¡rio de Sucesso ---
    
    @responses.activate
    def test_consulta_cnpj_existente(self, service):
        """CNPJ vÃ¡lido e existente retorna dados da empresa."""
        # Arrange: Mock da API
        responses.add(
            responses.GET,
            f"{self.BASE_URL}/11222333000181",
            json={
                "cnpj": "11.222.333/0001-81",
                "nome": "EMPRESA TESTE LTDA",
                "situacao": "ATIVA",
                "tipo": "MATRIZ"
            },
            status=200
        )
        
        # Act
        result = service.consultar("11222333000181")
        
        # Assert
        assert result.cnpj == "11.222.333/0001-81"
        assert result.nome == "EMPRESA TESTE LTDA"
        assert result.situacao == "ATIVA"
    
    # --- CenÃ¡rios de Erro ---
    
    @responses.activate
    def test_consulta_cnpj_inexistente(self, service):
        """CNPJ inexistente retorna erro 404."""
        # Arrange
        responses.add(
            responses.GET,
            f"{self.BASE_URL}/99999999999999",
            json={"message": "CNPJ nÃ£o encontrado"},
            status=404
        )
        
        # Act & Assert
        with pytest.raises(CNPJNotFoundError):
            service.consultar("99999999999999")
    
    @responses.activate
    def test_api_timeout(self, service):
        """Timeout da API Ã© tratado graciosamente."""
        # Arrange: Simula timeout
        responses.add(
            responses.GET,
            f"{self.BASE_URL}/11222333000181",
            body=requests.exceptions.Timeout()
        )
        
        # Act & Assert
        with pytest.raises(APITimeoutError) as exc:
            service.consultar("11222333000181")
        
        assert "timeout" in str(exc.value).lower()
    
    @responses.activate
    def test_api_rate_limit(self, service):
        """Rate limit (429) ativa retry com backoff."""
        # Arrange: Primeiro retorna 429, depois 200
        responses.add(
            responses.GET,
            f"{self.BASE_URL}/11222333000181",
            json={"message": "Rate limit exceeded"},
            status=429
        )
        responses.add(
            responses.GET,
            f"{self.BASE_URL}/11222333000181",
            json={"cnpj": "11.222.333/0001-81", "nome": "EMPRESA"},
            status=200
        )
        
        # Act
        result = service.consultar("11222333000181")
        
        # Assert
        assert result.cnpj == "11.222.333/0001-81"
        assert len(responses.calls) == 2  # Fez retry
    
    @responses.activate
    def test_resposta_malformada(self, service):
        """JSON invÃ¡lido Ã© tratado."""
        # Arrange
        responses.add(
            responses.GET,
            f"{self.BASE_URL}/11222333000181",
            body="not json",
            status=200
        )
        
        # Act & Assert
        with pytest.raises(InvalidResponseError):
            service.consultar("11222333000181")


class TestCNPJServiceContract:
    """Testes de contrato - validam schema da resposta."""
    
    @responses.activate
    def test_resposta_contem_campos_obrigatorios(self, service):
        """Resposta da API deve conter campos obrigatÃ³rios."""
        # Schema esperado
        required_fields = ["cnpj", "nome", "situacao", "tipo"]
        
        responses.add(
            responses.GET,
            f"{TestCNPJServiceIntegration.BASE_URL}/11222333000181",
            json={
                "cnpj": "11.222.333/0001-81",
                "nome": "EMPRESA",
                "situacao": "ATIVA",
                "tipo": "MATRIZ",
                # Campos extras sÃ£o OK
                "extra": "ignorado"
            },
            status=200
        )
        
        result = service.consultar("11222333000181")
        
        for field in required_fields:
            assert hasattr(result, field), f"Campo {field} ausente"
```

#### 5.4 ConfiguraÃ§Ã£o do Mock Server

```python
# conftest.py - Fixtures compartilhadas

import pytest
import responses

@pytest.fixture
def mock_api():
    """Ativa mocking de respostas HTTP."""
    with responses.RequestsMock() as rsps:
        yield rsps

@pytest.fixture
def mock_api_success(mock_api):
    """Mock prÃ©-configurado para sucesso."""
    mock_api.add(
        responses.GET,
        "https://receitaws.com.br/v1/cnpj/11222333000181",
        json={
            "cnpj": "11.222.333/0001-81",
            "nome": "EMPRESA TESTE LTDA",
            "situacao": "ATIVA",
            "tipo": "MATRIZ"
        },
        status=200
    )
    return mock_api
```

#### 5.5 EstratÃ©gia de ExecuÃ§Ã£o

```yaml
# .github/workflows/integration-tests.yml

integration-tests:
  runs-on: ubuntu-latest
  
  strategy:
    matrix:
      test-type: [mock, contract]
      include:
        - test-type: mock
          markers: "integration and not e2e"
        - test-type: contract  
          markers: "contract"
  
  steps:
    - name: Run Integration Tests
      run: |
        pytest tests/integration/ \
          -m "${{ matrix.markers }}" \
          --tb=short \
          -v

# Testes E2E rodam apenas em schedule (nÃ£o em cada PR)
e2e-tests:
  runs-on: ubuntu-latest
  if: github.event_name == 'schedule'
  
  steps:
    - name: Run E2E Tests
      env:
        RECEITA_API_KEY: ${{ secrets.RECEITA_API_KEY }}
      run: |
        pytest tests/e2e/ -m "e2e" --tb=long
```

### ğŸ’¡ Por Que Funciona

**1. Isolamento com Mocks**
- Testes nÃ£o dependem de API externa
- Rodam offline e em qualquer ambiente
- Controlamos exatamente o comportamento

**2. Cobertura de CenÃ¡rios**
- Sucesso, erro 404, timeout, rate limit, JSON invÃ¡lido
- ImpossÃ­vel testar todos estes cenÃ¡rios com API real

**3. Velocidade**
- Mocks respondem instantaneamente
- Pipeline rÃ¡pido = feedback rÃ¡pido

**4. Testes de Contrato**
- Garantem que nossa expectativa da API estÃ¡ correta
- Falham se API mudar (cedo)

### âš ï¸ Erros Comuns

1. **Mocks muito especÃ­ficos**
   - Se mock Ã© cÃ³pia exata da API, qualquer mudanÃ§a quebra
   - Mock deve capturar essÃªncia, nÃ£o detalhes

2. **NÃ£o testar cenÃ¡rios de erro**
   - 90% dos bugs estÃ£o em error handling
   - API sempre pode falhar de formas inesperadas

3. **Confundir mock com stub**
   - Mock: verifica interaÃ§Ãµes (foi chamado com X?)
   - Stub: retorna valor fixo
   - Use o correto para cada caso

4. **Testes E2E demais**
   - Caros, lentos, flaky
   - Use para smoke tests apenas

### ğŸ”„ Alternativas AceitÃ¡veis

- Usar `httpretty` ou `vcr.py` ao invÃ©s de `responses`
- WireMock para mock server mais robusto
- Pact para testes de contrato consumer-driven

### ğŸ“š ConexÃ£o com a Teoria

- [03-como-funciona.md](../02-guia-teorico/03-como-funciona.md) - PirÃ¢mide de Testes
- [04-como-aplicar.md](../02-guia-teorico/04-como-aplicar.md) - EstratÃ©gias de Mocking

### ğŸ¯ Pontos de DiscussÃ£o

1. "Quando usar mock vs API real?"
2. "Como manter mocks sincronizados com API real?"
3. "Testes de contrato sÃ£o responsabilidade de quem?"

---

## ExercÃ­cio 6: MÃ©tricas e Monitoramento

### ğŸ“‹ Enunciado Resumido
Definir mÃ©tricas para medir efetividade de Shift Left no projeto CNPJ.

### âœ… Resposta Esperada

#### 6.1 Framework de MÃ©tricas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MÃ‰TRICAS SHIFT LEFT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   LEADING (Preditivas)          LAGGING (Resultados)            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚ â€¢ Cobertura cÃ³digo  â”‚       â”‚ â€¢ Bugs em produÃ§Ã£o  â”‚         â”‚
â”‚   â”‚ â€¢ Testes por commit â”‚  â”€â”€â–¶  â”‚ â€¢ MTTR (tempo fix)  â”‚         â”‚
â”‚   â”‚ â€¢ Tempo de build    â”‚       â”‚ â€¢ Custo de defeitos â”‚         â”‚
â”‚   â”‚ â€¢ Review coverage   â”‚       â”‚ â€¢ SatisfaÃ§Ã£o user   â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                  â”‚
â”‚   PROCESSO                      QUALIDADE                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚ â€¢ Lead time         â”‚       â”‚ â€¢ Taxa de defeitos  â”‚         â”‚
â”‚   â”‚ â€¢ Cycle time        â”‚       â”‚ â€¢ Escape rate       â”‚         â”‚
â”‚   â”‚ â€¢ Deploy frequency  â”‚       â”‚ â€¢ Test pass rate    â”‚         â”‚
â”‚   â”‚ â€¢ Automation %      â”‚       â”‚ â€¢ Tech debt ratio   â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 6.2 MÃ©tricas EspecÃ­ficas

| MÃ©trica | FÃ³rmula | Meta | FrequÃªncia |
|---------|---------|------|------------|
| **Code Coverage** | Linhas testadas / Total linhas | â‰¥ 80% | Por commit |
| **Test Pass Rate** | Testes passando / Total testes | â‰¥ 95% | Por build |
| **Build Time** | Tempo total do pipeline | < 10 min | Por build |
| **Defect Escape Rate** | Bugs produÃ§Ã£o / Total bugs | < 10% | Semanal |
| **MTTR** | Tempo mÃ©dio para corrigir | < 4h | Por incidente |
| **Lead Time** | Commit atÃ© produÃ§Ã£o | < 1 dia | Por deploy |

#### 6.3 Dashboard de MÃ©tricas

```python
"""
Coletor de mÃ©tricas Shift Left para o projeto CNPJ.
Integra com GitHub Actions e gera relatÃ³rios.
"""
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import List, Dict
import json


@dataclass
class ShiftLeftMetrics:
    """Container para mÃ©tricas Shift Left."""
    
    # Cobertura
    line_coverage: float = 0.0
    branch_coverage: float = 0.0
    
    # Velocidade
    build_time_seconds: int = 0
    test_execution_time: int = 0
    
    # Qualidade
    tests_total: int = 0
    tests_passed: int = 0
    tests_failed: int = 0
    tests_skipped: int = 0
    
    # Defeitos
    bugs_found_dev: int = 0
    bugs_found_qa: int = 0
    bugs_found_prod: int = 0
    
    # Timestamps
    collected_at: datetime = field(default_factory=datetime.now)
    
    @property
    def test_pass_rate(self) -> float:
        """Taxa de testes passando."""
        if self.tests_total == 0:
            return 0.0
        return (self.tests_passed / self.tests_total) * 100
    
    @property
    def defect_escape_rate(self) -> float:
        """Taxa de defeitos que escaparam para produÃ§Ã£o."""
        total_bugs = self.bugs_found_dev + self.bugs_found_qa + self.bugs_found_prod
        if total_bugs == 0:
            return 0.0
        return (self.bugs_found_prod / total_bugs) * 100
    
    @property
    def shift_left_score(self) -> float:
        """
        Score composto de efetividade Shift Left (0-100).
        
        Componentes:
        - Cobertura (30%): 80%+ = mÃ¡ximo
        - Pass Rate (25%): 95%+ = mÃ¡ximo
        - Build Time (20%): <10min = mÃ¡ximo
        - Escape Rate (25%): <10% = mÃ¡ximo
        """
        coverage_score = min(self.line_coverage / 80, 1.0) * 30
        pass_rate_score = min(self.test_pass_rate / 95, 1.0) * 25
        
        # Build time: 10 min = 600s
        build_score = max(0, (600 - self.build_time_seconds) / 600) * 20
        
        # Escape rate: quanto menor, melhor
        escape_score = max(0, (100 - self.defect_escape_rate) / 90) * 25
        
        return coverage_score + pass_rate_score + build_score + escape_score
    
    def to_dict(self) -> Dict:
        """Converte para dicionÃ¡rio para exportaÃ§Ã£o."""
        return {
            "coverage": {
                "line": self.line_coverage,
                "branch": self.branch_coverage
            },
            "tests": {
                "total": self.tests_total,
                "passed": self.tests_passed,
                "failed": self.tests_failed,
                "skipped": self.tests_skipped,
                "pass_rate": self.test_pass_rate
            },
            "performance": {
                "build_time_seconds": self.build_time_seconds,
                "test_time_seconds": self.test_execution_time
            },
            "quality": {
                "bugs_dev": self.bugs_found_dev,
                "bugs_qa": self.bugs_found_qa,
                "bugs_prod": self.bugs_found_prod,
                "escape_rate": self.defect_escape_rate
            },
            "score": {
                "shift_left_score": self.shift_left_score,
                "grade": self._get_grade()
            },
            "collected_at": self.collected_at.isoformat()
        }
    
    def _get_grade(self) -> str:
        """Retorna nota baseada no score."""
        score = self.shift_left_score
        if score >= 90:
            return "A"
        elif score >= 80:
            return "B"
        elif score >= 70:
            return "C"
        elif score >= 60:
            return "D"
        return "F"


class MetricsCollector:
    """Coleta mÃ©tricas de vÃ¡rias fontes."""
    
    def __init__(self):
        self.metrics = ShiftLeftMetrics()
    
    def collect_from_pytest(self, report_path: str) -> None:
        """Coleta mÃ©tricas do relatÃ³rio pytest."""
        # ImplementaÃ§Ã£o lÃª coverage.xml e pytest report
        pass
    
    def collect_from_github(self, repo: str) -> None:
        """Coleta mÃ©tricas do GitHub Actions."""
        # ImplementaÃ§Ã£o usa GitHub API
        pass
    
    def generate_report(self) -> str:
        """Gera relatÃ³rio em formato markdown."""
        m = self.metrics
        
        report = f"""
# ğŸ“Š RelatÃ³rio Shift Left - {m.collected_at.strftime('%Y-%m-%d')}

## Score Geral: {m.shift_left_score:.1f}/100 ({m._get_grade()})

### Cobertura de CÃ³digo
| MÃ©trica | Valor | Meta | Status |
|---------|-------|------|--------|
| Linhas | {m.line_coverage:.1f}% | 80% | {'âœ…' if m.line_coverage >= 80 else 'âš ï¸'} |
| Branches | {m.branch_coverage:.1f}% | 70% | {'âœ…' if m.branch_coverage >= 70 else 'âš ï¸'} |

### ExecuÃ§Ã£o de Testes
| MÃ©trica | Valor | Meta | Status |
|---------|-------|------|--------|
| Total | {m.tests_total} | - | - |
| Passando | {m.tests_passed} ({m.test_pass_rate:.1f}%) | 95% | {'âœ…' if m.test_pass_rate >= 95 else 'âš ï¸'} |
| Falhando | {m.tests_failed} | 0 | {'âœ…' if m.tests_failed == 0 else 'âŒ'} |

### Performance
| MÃ©trica | Valor | Meta | Status |
|---------|-------|------|--------|
| Build Time | {m.build_time_seconds}s | <600s | {'âœ…' if m.build_time_seconds < 600 else 'âš ï¸'} |
| Test Time | {m.test_execution_time}s | <300s | {'âœ…' if m.test_execution_time < 300 else 'âš ï¸'} |

### Qualidade
| MÃ©trica | Valor | Meta | Status |
|---------|-------|------|--------|
| Escape Rate | {m.defect_escape_rate:.1f}% | <10% | {'âœ…' if m.defect_escape_rate < 10 else 'âŒ'} |
| Bugs Dev | {m.bugs_found_dev} | - | âœ… (encontrados cedo) |
| Bugs Prod | {m.bugs_found_prod} | 0 | {'âœ…' if m.bugs_found_prod == 0 else 'âŒ'} |

---
*RelatÃ³rio gerado automaticamente pelo Shift Left Metrics Collector*
"""
        return report
```

#### 6.4 IntegraÃ§Ã£o com CI/CD

```yaml
# .github/workflows/metrics.yml

name: Collect Shift Left Metrics

on:
  workflow_run:
    workflows: ["CI/CD Pipeline"]
    types: [completed]

jobs:
  collect-metrics:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: coverage-report
          
      - name: Collect Metrics
        run: |
          python scripts/collect_metrics.py \
            --coverage coverage.xml \
            --output metrics.json
            
      - name: Update Dashboard
        run: |
          python scripts/update_dashboard.py \
            --metrics metrics.json \
            --output docs/metrics/latest.md
            
      - name: Check Thresholds
        run: |
          python scripts/check_thresholds.py \
            --metrics metrics.json \
            --fail-on-regression
```

### ğŸ’¡ Por Que Funciona

**1. MÃ©tricas Balanceadas**
- Leading indicators preveem problemas
- Lagging indicators confirmam resultados
- Processo + Qualidade = visÃ£o completa

**2. AutomaÃ§Ã£o**
- Coleta automÃ¡tica = dados consistentes
- Sem trabalho manual = sustentÃ¡vel
- Integrado no pipeline = sempre atualizado

**3. Score Composto**
- Uma mÃ©trica nÃ£o conta a histÃ³ria toda
- Score balanceado evita gaming
- FÃ¡cil de comunicar para gestÃ£o

**4. Thresholds Claros**
- Metas definidas = expectativas claras
- Alertas automÃ¡ticos = aÃ§Ã£o rÃ¡pida
- TendÃªncias = melhoria contÃ­nua

### âš ï¸ Erros Comuns

1. **MÃ©tricas demais**
   - Escolha 5-7 mÃ©tricas principais
   - Mais que isso = paralisia por anÃ¡lise

2. **Otimizar mÃ©trica em vez de resultado**
   - 100% cobertura com testes ruins = inÃºtil
   - MÃ©tricas sÃ£o proxies, nÃ£o objetivos

3. **NÃ£o agir nos dados**
   - Coletar mÃ©tricas e ignorar = desperdÃ­cio
   - Defina aÃ§Ãµes para cada threshold violado

4. **Comparar equipes diretamente**
   - Contextos diferentes = mÃ©tricas diferentes
   - Compare evoluÃ§Ã£o, nÃ£o valores absolutos

### ğŸ“š ConexÃ£o com a Teoria

- [05-lembrar-sempre.md](../02-guia-teorico/05-lembrar-sempre.md) - MÃ©tricas e Sustentabilidade

---

## ğŸ“Š Resumo da AvaliaÃ§Ã£o - NÃ­vel IntermediÃ¡rio

| ExercÃ­cio | Pontos | CritÃ©rios |
|-----------|--------|-----------|
| 4 | 35 | AnÃ¡lise crÃ­tica + RefatoraÃ§Ã£o + Testes |
| 5 | 35 | EstratÃ©gia mock + Cobertura cenÃ¡rios |
| 6 | 30 | Framework mÃ©tricas + ImplementaÃ§Ã£o |
| **Total** | **100** | |

### PrÃ³ximos Passos

- **90-100**: Pronto para nÃ­vel avanÃ§ado
- **75-89**: RevisÃ£o focada em gaps
- **60-74**: Praticar mais exercÃ­cios similares
- **< 60**: Revisar teoria e bÃ¡sico

---

| Anterior | Ãndice | PrÃ³ximo |
|----------|--------|---------|
| [â† BÃ¡sico](01-nivel-basico.md) | [ğŸ“š Principal](../README.md) | [AvanÃ§ado â†’](03-nivel-avancado.md) |
